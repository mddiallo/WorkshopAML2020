{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Hyperdrive avec Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/retkowsky/images/blob/master/AzureMLservicebanniere.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Efficiently tune hyperparameters** for your model using Azure Machine Learning.<br>\n",
    "**Hyperparameter tuning** includes the following steps:\n",
    "<br>\n",
    "- Define the parameter search space<br>\n",
    "- Specify a primary metric to optimize<br>\n",
    "- Specify early termination criteria for poorly performing runs<br>\n",
    "- Allocate resources for hyperparameter tuning<br>\n",
    "- Launch an experiment with the above configuration<br>\n",
    "- Visualize the training runs<br>\n",
    "- Select the best performing configuration for your model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation Hyperdrive avec Azure ML :\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "print(\"Version Azure ML service : \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace Azure ML :', ws.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ComputeTarget, Datastore, Dataset\n",
    "\n",
    "print(\"Compute Targets:\")\n",
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(\"\\t\", compute.name, ':', compute.type)\n",
    "    \n",
    "print(\"Datastores:\")\n",
    "for datastore_name in ws.datastores:\n",
    "    datastore = Datastore.get(ws, datastore_name)\n",
    "    print(\"\\t\", datastore.name, ':', datastore.datastore_type)\n",
    "    \n",
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperdrive pour trouver la meilleure combinaison\n",
    "\n",
    "The remote compute you created is a four-node cluster, and you can take advantage of this to execute multiple experiment runs in parallel. One key reason to do this is to try training a model with a range of different hyperparameter values.\n",
    "\n",
    "Azure ML includes a feature called *hyperdrive* that enables you to randomly try different values for one or more hyperparameters, and find the best performing trained model based on a metric that you specify - such as *Accuracy* or *Area Under the Curve (AUC)*.\n",
    "\n",
    "> **More Information**: For more information about Hyperdrive, see the [Azure ML documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters).\n",
    "\n",
    "Let's run a Hyperdrive experiment on the remote compute you have provisioned. First, we'll create the experiment and its associated folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expérimentation\n",
    "hyperdrive_experiment_name = 'Exemple14-Scikit-Learn-HyperDrive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_experiment = Experiment(workspace = ws, name = hyperdrive_experiment_name)\n",
    "\n",
    "hyperdrive_experiment_folder = './' + hyperdrive_experiment_name\n",
    "os.makedirs(hyperdrive_experiment_folder, exist_ok=True)\n",
    "\n",
    "print(\"Expérimentation :\", hyperdrive_experiment.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $hyperdrive_experiment_folder/diabetes_training.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "print(\"Chargement des données...\")\n",
    "diabetes = run.input_datasets['diabetes'].to_pandas_dataframe()\n",
    "\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Partitionnement\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Modélisation\n",
    "print('Régression logistique avec taux de régularisation', reg)\n",
    "run.log('Taux de régularisation',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy =', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC =' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Courbe de ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe de ROC')\n",
    "run.log_image(name = \"ROC\", plot = fig)\n",
    "plt.show()\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "joblib.dump(value=model, filename='outputs/diabetes.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls Exemple14-Scikit-Learn-HyperDrive/diabetes_training.py -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the yml file\n",
    "with open(os.path.join('./Exemple14-Scikit-Learn-HyperDrive/diabetes_training.py'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"cpu-standardd4\"\n",
    "\n",
    "try:\n",
    "    compute1 = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D4', min_nodes=1, max_nodes=10)\n",
    "    compute1 = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute1.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des clusters\n",
    "liste = ws.compute_targets\n",
    "for liste in liste:\n",
    "    print(\"Ressources compute du workspace :\", liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de tags pour le run\n",
    "tagsdurun = {\"Type\": \"test\" , \"Langage\" : \"Python\" , \"Framework\" : \"Scikit-Learn\" , \"Hyperdrive\" : \"Gridsearch\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import GridParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import choice\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "# Grid Search\n",
    "params = GridParameterSampling(\n",
    "    {\n",
    "        # Différentes valeurs du paramétre de régularisation à tester\n",
    "        '--regularization': choice(0.0005, 0.005, 0.01, 0.1)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Policy Bandit is an early termination policy based on slack factor/slack amount and evaluation interval. \n",
    "# The policy early terminates any runs where the primary metric is not within the specified slack factor/slack amount \n",
    "# with respect to the best performing training run.\n",
    "\n",
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "# Données\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Définition estimateur\n",
    "hyper_estimator = SKLearn(source_directory=hyperdrive_experiment_folder,\n",
    "                           inputs=[diabetes_ds.as_named_input('diabetes')], # Données en entrée\n",
    "                           compute_target = compute1, # Compute server\n",
    "                           conda_packages=['pandas','ipykernel','matplotlib'], #Dépendances\n",
    "                           pip_packages=['azureml-sdk','argparse','pyarrow'], \n",
    "                           entry_script='diabetes_training.py')  # script Python\n",
    "\n",
    "# Configuration hyperdrive\n",
    "hyperdrive = HyperDriveConfig(estimator=hyper_estimator, \n",
    "                          hyperparameter_sampling=params, # Paramétres\n",
    "                          policy=policy, #Policy\n",
    "                          primary_metric_name='Accuracy', #Métrique\n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, #Optimisation de la métrique\n",
    "                          max_total_runs=10,\n",
    "                          max_concurrent_runs=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation:\n",
    "    https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.banditpolicy?view=azure-ml-py\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "hyperdrive_run = hyperdrive_experiment.submit(config=hyperdrive, tags=tagsdurun)\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Temps de traitement : autour de **10 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progression du run\n",
    "hyperdrive_run.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On récupère le best run :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperdrive_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_hyperdrive_run_metrics = best_hyperdrive_run.get_metrics()\n",
    "hyperdrive_parameter_values = best_hyperdrive_run.get_details() ['runDefinition']['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Résultats du best run de l'hyperparameter Tuning :\")\n",
    "print()\n",
    "print('Best Run ID =', best_hyperdrive_run.id)\n",
    "print()\n",
    "print('Regularization Rate optimal =', hyperdrive_parameter_values)\n",
    "print()\n",
    "print('Métriques :')\n",
    "print(' - AUC =', best_hyperdrive_run_metrics['AUC'])\n",
    "print(' - Accuracy =', best_hyperdrive_run_metrics['Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On référence le meilleur modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "best_hyperdrive_run.register_model(model_path='outputs/diabetes.pkl', \n",
    "                                   model_name='Diabetes',\n",
    "                                   tags={'Training context':'Hyperdrive'},\n",
    "                                   properties={'AUC': best_hyperdrive_run_metrics['AUC'],\n",
    "                                               'Accuracy': best_hyperdrive_run_metrics['Accuracy']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Le modèle est disponible dans le section **Models** d'Azure ML Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liste des modèles référencés dans le workspace Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des modèles référencés\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, '- version =', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression du compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, \"(\" , ct.type, \") :\", ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression du cluster\n",
    "#compute1.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, \"(\" , ct.type, \") :\", ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/retkowsky/images/blob/master/Powered-by-MS-Azure-logo-v2.png?raw=true\" height=\"300\" width=\"300\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
